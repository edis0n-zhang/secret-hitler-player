{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'secret-hitler-strategy'\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072, # Replace with your model dimensions\n",
    "        metric=\"cosine\", # Replace with your model metric\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        ) \n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mdsplit import PathBasedSplitter\n",
    "\n",
    "# splitter = PathBasedSplitter('./tartanllama.md', 'utf8', 5, True, './out', False, False)\n",
    "# splitter.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "for dir_path, dirs, files in os.walk('./out'):\n",
    "    for file_name in files:\n",
    "        if not Path(file_name).suffix == \".md\": continue\n",
    "        file_path = Path(dir_path) / file_name\n",
    "\n",
    "        with open (file_path, 'r') as f:\n",
    "            filetext = f.readlines()\n",
    "            vectors = []\n",
    "\n",
    "            for line in filetext:\n",
    "                if line in ('\\n', ' ', '\\t'):\n",
    "                    continue\n",
    "\n",
    "                response = client.embeddings.create(\n",
    "                    model=\"text-embedding-3-large\",\n",
    "                    input=line,\n",
    "                    encoding_format=\"float\"\n",
    "                )\n",
    "\n",
    "                vectors.append({\n",
    "                    'metadata': { 'text': line },\n",
    "                    'id': str(file_path),\n",
    "                    'values': response.data[0].embedding,\n",
    "                })\n",
    "\n",
    "            if len(vectors) > 0:\n",
    "                index.upsert(vectors=vectors, namespace='tartanllama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
